{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49b07c8-f4df-42ab-a3e2-d3cb993cb9e7",
   "metadata": {},
   "source": [
    "<style>\n",
    "  .md-typeset h1,\n",
    "  .md-content__button {\n",
    "    display: none;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "\n",
    "<h2>Building Q&A Application with LlamaIndex and Amazon Bedrock Knowledge Base</h2>\n",
    "\n",
    "\n",
    "<a href=\"https://github.com/aws-samples/amazon-bedrock-samples/opensource-libraries/knowledge-base/2_how_to_use_knowledge_base_with_llamaindex.ipynb\">Open in Github</a>\n",
    "\n",
    "\n",
    "<h2>Overview</h2>\n",
    "\n",
    "In this notebook we will leverage Amazon Bedrock Knowledge Base that we created in <a href=\"https://github.com/aws-samples/amazon-bedrock-samples/opensource-libraries/knowledge-base/0_how_to_create_index_and_ingest_documents_in_knowledge_base.ipynb\">0_how_to_create_index_and_ingest_documents_in_knowledge_base.ipynb</a> and use it with LlamaIndex to create a Q&A Application.\n",
    "\n",
    "\n",
    "<h2>Context</h2>\n",
    "\n",
    "Implementing RAG requires organizations to perform several cumbersome steps to convert data into embeddings (vectors), store the embeddings in a specialized vector database, and build custom integrations into the database to search and retrieve text relevant to the user’s query. This can be time-consuming and inefficient.\n",
    "\n",
    "With Knowledge Bases for Amazon Bedrock, simply point to the location of your data in Amazon S3, and Knowledge Bases for Amazon Bedrock takes care of the entire ingestion workflow into your vector database. If you do not have an existing vector database, Amazon Bedrock creates an Amazon OpenSearch Serverless vector store for you. For retrievals, use the LLamaIndex - Amazon Bedrock integration via the Retrieve API to retrieve relevant results for a user query from knowledge bases.\n",
    "\n",
    "In this notebook, we will dive deep into building Q&A application. We will query the knowledge base to get the desired number of document chunks based on similarity search, integrate it with LlamaIndex retriever and use Anthropic Claude 3 Haiku model from Amazon Bedrock for answering questions.\n",
    "\n",
    "Following is the Architecture Diagram of the orchestration done by LlamaIndex by leveraging Large Language Model and Knowledge Base from Amazon Bedrock\n",
    "\n",
    "<img src=\"./assets/images/retrieveAPI.png\" alt=\"Custom RAG Workflow\" style=\"margin:auto\">\n",
    "\n",
    "<h2>Prerequisites</h2>\n",
    "\n",
    "Before being able to answer the questions, the documents must be processed and ingested in vector database as shown on [0_how_to_create_index_and_ingest_documents_in_knowledge_base.ipynb](./0\\_how_to_create_index_and_ingest_documents_in_knowledge_base.ipynb). We will making use of the Knowledge Base ID that we stored in this notebook.\n",
    "\n",
    "In case you are wanting to create the Knowledge Base from Console then you can follow the [official documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base-create.html).\n",
    "\n",
    "<h3>Dataset</h3>\n",
    "\n",
    "In this example, you will use several years of Amazon's Letter to Shareholders as a text corpus to perform Q&A on. This data is already ingested into the Knowledge Bases for Amazon Bedrock. You will need the `knowledge_base_id` to run this example. In your specific use case, you can sync different files for different domain topics and query this notebook in the same manner to evaluate model responses using the retrieve API from knowledge bases.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> This notebook has been tested in <strong>Mumbai (ap-south-1)</strong> in <strong>Python 3.10.14</strong>\n",
    "</div>\n",
    "\n",
    "<h2>Setup</h2>\n",
    "\n",
    "To run this notebook you would need to install following packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3704bf34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3==1.34.162 in /opt/conda/lib/python3.10/site-packages (1.34.162)\n",
      "Requirement already satisfied: botocore==1.34.162 in /opt/conda/lib/python3.10/site-packages (1.34.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3==1.34.162) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3==1.34.162) (0.10.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore==1.34.162) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore==1.34.162) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.34.162) (1.16.0)\n",
      "Collecting llama-index==0.10.30\n",
      "  Using cached llama_index-0.10.30-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-retrievers-bedrock==0.1.1\n",
      "  Using cached llama_index_retrievers_bedrock-0.1.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting llama-index-llms-bedrock==0.1.6\n",
      "  Using cached llama_index_llms_bedrock-0.1.6-py3-none-any.whl.metadata (687 bytes)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.30 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /opt/conda/lib/python3.10/site-packages (from llama-index==0.10.30) (0.9.48.post3)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index==0.10.30)\n",
      "  Using cached llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.34.26 in /opt/conda/lib/python3.10/site-packages (from llama-index-llms-bedrock==0.1.6) (1.34.162)\n",
      "Collecting llama-index-llms-anthropic<0.2.0,>=0.1.7 (from llama-index-llms-bedrock==0.1.6)\n",
      "  Using cached llama_index_llms_anthropic-0.1.17-py3-none-any.whl.metadata (691 bytes)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.162 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock==0.1.6) (1.34.162)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock==0.1.6) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock==0.1.6) (0.10.2)\n",
      "Requirement already satisfied: openai>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.30) (1.43.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (2023.6.0)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (0.27.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (3.3)\n",
      "Requirement already satisfied: nltk!=3.9,>=3.8.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (2.1.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (2.7.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.14.1)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.19 in /opt/conda/lib/python3.10/site-packages (from llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2->llama-index==0.10.30) (0.1.19)\n",
      "Requirement already satisfied: anthropic<0.29.0,>=0.26.2 in /opt/conda/lib/python3.10/site-packages (from llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.6) (0.28.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.30) (4.12.3)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.30) (4.3.1)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.30) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.30) (0.5.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (4.0.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.6) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.6) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.6) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.6) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.6) (0.19.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.30) (2.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.162->boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock==0.1.6) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.162->boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock==0.1.6) (1.26.19)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (0.14.0)\n",
      "INFO: pip is looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.30)\n",
      "  Using cached llama_parse-0.5.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Using cached llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "  Using cached llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (2024.7.24)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (3.21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.6) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.30->llama-index==0.10.30) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.162->boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock==0.1.6) (1.16.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.0->anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.6) (0.24.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock==0.1.6) (3.15.4)\n",
      "Using cached llama_index-0.10.30-py3-none-any.whl (6.9 kB)\n",
      "Using cached llama_index_retrievers_bedrock-0.1.1-py3-none-any.whl (3.7 kB)\n",
      "Using cached llama_index_llms_bedrock-0.1.6-py3-none-any.whl (8.2 kB)\n",
      "Using cached llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "Using cached llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
      "Using cached llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "Using cached llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
      "Using cached llama_index_llms_anthropic-0.1.17-py3-none-any.whl (6.6 kB)\n",
      "Using cached llama_index_llms_openai-0.1.31-py3-none-any.whl (12 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n",
      "Using cached llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
      "Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "Using cached llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Installing collected packages: llama-index-core, llama-parse, llama-index-retrievers-bedrock, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-llms-anthropic, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-llms-bedrock, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.11.5\n",
      "    Uninstalling llama-index-core-0.11.5:\n",
      "      Successfully uninstalled llama-index-core-0.11.5\n",
      "  Attempting uninstall: llama-parse\n",
      "    Found existing installation: llama-parse 0.5.2\n",
      "    Uninstalling llama-parse-0.5.2:\n",
      "      Successfully uninstalled llama-parse-0.5.2\n",
      "  Attempting uninstall: llama-index-retrievers-bedrock\n",
      "    Found existing installation: llama-index-retrievers-bedrock 0.2.0\n",
      "    Uninstalling llama-index-retrievers-bedrock-0.2.0:\n",
      "      Successfully uninstalled llama-index-retrievers-bedrock-0.2.0\n",
      "  Attempting uninstall: llama-index-readers-file\n",
      "    Found existing installation: llama-index-readers-file 0.2.0\n",
      "    Uninstalling llama-index-readers-file-0.2.0:\n",
      "      Successfully uninstalled llama-index-readers-file-0.2.0\n",
      "  Attempting uninstall: llama-index-llms-openai\n",
      "    Found existing installation: llama-index-llms-openai 0.2.2\n",
      "    Uninstalling llama-index-llms-openai-0.2.2:\n",
      "      Successfully uninstalled llama-index-llms-openai-0.2.2\n",
      "  Attempting uninstall: llama-index-indices-managed-llama-cloud\n",
      "    Found existing installation: llama-index-indices-managed-llama-cloud 0.3.0\n",
      "    Uninstalling llama-index-indices-managed-llama-cloud-0.3.0:\n",
      "      Successfully uninstalled llama-index-indices-managed-llama-cloud-0.3.0\n",
      "  Attempting uninstall: llama-index-embeddings-openai\n",
      "    Found existing installation: llama-index-embeddings-openai 0.2.4\n",
      "    Uninstalling llama-index-embeddings-openai-0.2.4:\n",
      "      Successfully uninstalled llama-index-embeddings-openai-0.2.4\n",
      "  Attempting uninstall: llama-index-readers-llama-parse\n",
      "    Found existing installation: llama-index-readers-llama-parse 0.3.0\n",
      "    Uninstalling llama-index-readers-llama-parse-0.3.0:\n",
      "      Successfully uninstalled llama-index-readers-llama-parse-0.3.0\n",
      "  Attempting uninstall: llama-index-multi-modal-llms-openai\n",
      "    Found existing installation: llama-index-multi-modal-llms-openai 0.2.0\n",
      "    Uninstalling llama-index-multi-modal-llms-openai-0.2.0:\n",
      "      Successfully uninstalled llama-index-multi-modal-llms-openai-0.2.0\n",
      "  Attempting uninstall: llama-index-llms-anthropic\n",
      "    Found existing installation: llama-index-llms-anthropic 0.2.1\n",
      "    Uninstalling llama-index-llms-anthropic-0.2.1:\n",
      "      Successfully uninstalled llama-index-llms-anthropic-0.2.1\n",
      "  Attempting uninstall: llama-index-cli\n",
      "    Found existing installation: llama-index-cli 0.3.0\n",
      "    Uninstalling llama-index-cli-0.3.0:\n",
      "      Successfully uninstalled llama-index-cli-0.3.0\n",
      "  Attempting uninstall: llama-index-agent-openai\n",
      "    Found existing installation: llama-index-agent-openai 0.3.0\n",
      "    Uninstalling llama-index-agent-openai-0.3.0:\n",
      "      Successfully uninstalled llama-index-agent-openai-0.3.0\n",
      "  Attempting uninstall: llama-index-program-openai\n",
      "    Found existing installation: llama-index-program-openai 0.2.0\n",
      "    Uninstalling llama-index-program-openai-0.2.0:\n",
      "      Successfully uninstalled llama-index-program-openai-0.2.0\n",
      "  Attempting uninstall: llama-index-llms-bedrock\n",
      "    Found existing installation: llama-index-llms-bedrock 0.2.1\n",
      "    Uninstalling llama-index-llms-bedrock-0.2.1:\n",
      "      Successfully uninstalled llama-index-llms-bedrock-0.2.1\n",
      "  Attempting uninstall: llama-index-question-gen-openai\n",
      "    Found existing installation: llama-index-question-gen-openai 0.2.0\n",
      "    Uninstalling llama-index-question-gen-openai-0.2.0:\n",
      "      Successfully uninstalled llama-index-question-gen-openai-0.2.0\n",
      "  Attempting uninstall: llama-index\n",
      "    Found existing installation: llama-index 0.11.5\n",
      "    Uninstalling llama-index-0.11.5:\n",
      "      Successfully uninstalled llama-index-0.11.5\n",
      "Successfully installed llama-index-0.10.30 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.68.post1 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-llms-anthropic-0.1.17 llama-index-llms-bedrock-0.1.6 llama-index-llms-openai-0.1.31 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-index-retrievers-bedrock-0.1.1 llama-parse-0.4.9\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade boto3==1.34.162 botocore==1.34.162\n",
    "# !pip install --upgrade llama-index==0.11.5 llama-index-retrievers-bedrock==0.2.0 llama-index-llms-bedrock==0.2.1\n",
    "!pip install --upgrade llama-index==0.10.30 llama-index-retrievers-bedrock==0.1.1 llama-index-llms-bedrock==0.1.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13369e",
   "metadata": {},
   "source": [
    "<strong>Restart the kernel with the updated packages that are installed through the dependencies above</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98531c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7984495",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>\n",
    "\n",
    "<b>Follow the steps below to initilize the required python modules</b>\n",
    "\n",
    "<ol>\n",
    "<li>Import necessary libraries and initialize bedrock client required by the Langchain module to communicate with Foundation Models (FM) or Large Language Models (LLM) available in Amazon Bedrock.</li>\n",
    "<li>Import and Initialize Knoweledge Base Retriver available in LlamaIndex to communicate with Knowledge Base from Amazon Bedrock</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae08094-e5c1-4eac-9d80-9fd2b42d1442",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note :</b> If the following cell execution gives you error then please manually restart the kernel, the error will go away.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d63b63b-278e-4c65-b2ab-752ee24922e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /opt/conda/lib/python3.10/site-\n",
      "[nltk_data]     packages/llama_index/core/_static/nltk_cache...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "import json\n",
    "\n",
    "import llama_index\n",
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.llms.bedrock.base import Bedrock\n",
    "from llama_index.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n",
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a747a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "805af769",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name   # use can you the region of your choice.\n",
    "botocore_config = Config(\n",
    "    connect_timeout=120, read_timeout=120, retries={'max_attempts': 0}\n",
    ")\n",
    "# bedrock_client = boto3.client('bedrock-runtime', region_name=region)\n",
    "\n",
    "llm = Bedrock(\n",
    "    region_name=region,\n",
    "    botocore_config= botocore_config,\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\", # Model ID of the LLM of our choice from Amazon Bedrock\n",
    "    temperature=0, \n",
    "    max_tokens=3000\n",
    ")\n",
    "\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "    knowledge_base_id=kb_id, # we are using the id of the knowledge base that we created in earlier notebook\n",
    "    retrieval_config={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\": 3,\n",
    "            \"overrideSearchType\": \"HYBRID\",\n",
    "            # \"filter\": {\"equals\": {\"key\": \"tag\", \"value\": \"space\"}}, # Optional Field for for metadata filtering.\n",
    "        }\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccddbab",
   "metadata": {},
   "source": [
    "Above we initialized the following two objects from Langchain:\n",
    "<ol>\n",
    "<li><strong>ChatBedrock</strong> - This object will orchestrates the communication with  the LLM from Amazon Bedrock. It will take care of structuring the prompt/messages, model arguments, etc for us whenever it invokes the LLM.</li>\n",
    "<li><strong>AmazonKnowledgeBasesRetriever</strong> - This objects will calls APIs of Knowledge Bases for Amazon Bedrock which converts user queries into embeddings, searches the knowledge base, and returns the relevant results, giving you more control to build custom workﬂows on top of the semantic search results.</li>\n",
    "</ol>\n",
    "\n",
    "<h3>Usage</h3>\n",
    "\n",
    "Below is the method to directly fetch the relevant documents usign the `AmazonKnowledgeBasesRetriever` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd87c9b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ NodeWithScore(node=TextNode(id_='20968c02-db9c-4ce7-9b1a-6e33a7ff22e4', embedding=None, metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2021-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'sourceMetadata': {'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2021-Shareholder-Letter.pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AtdzPwpEBFLS6KFZCDq4s', 'x-amz-bedrock-kb-data-source-id': 'QSPUTYFUTO'}}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='This was due in part to the uncertainty and slowing demand that so many businesses encountered, but also in part to our helping companies optimize their AWS footprint to save money. Concurrently, companies were stepping back and determining what they wanted to change coming out of the pandemic. Many concluded that they didn’t want to continue managing their technology infrastructure themselves, and made the decision to accelerate their move to the cloud. This shift by so many companies (along with the economy recovering) helped re-accelerate AWS’s revenue growth to 37% YoY in 2021.   Conversely, our Consumer revenue grew dramatically in 2020. In 2020, Amazon’s North America and International Consumer revenue grew 39% YoY on the very large 2019 revenue base of $245 billion; and, this extraordinary growth extended into 2021 with revenue increasing 43% YoY in Q1 2021. These are astounding numbers. We realized the equivalent of three years’ forecasted growth in about 15 months.   As the world opened up again starting in late Q2 2021, and more people ventured out to eat, shop, and travel, consumer spending returned to being spread over many more entities. We weren’t sure what to expect in 2021, but the fact that we continued to grow at double digit rates (with a two-year Consumer compounded annual growth rate of 29%) was encouraging as customers appreciated the role Amazon played for them during the pandemic, and started using Amazon for a larger amount of their household purchases.   This growth also created short-term logistics and cost challenges. We spent Amazon’s first 25 years building a very large fulfillment network, and then had to double it in the last 24 months to meet customer demand. As we were bringing this new capacity online, the labor market tightened considerably, making it challenging both to receive all of the inventory our vendors and sellers wanted to send us and to place that inventory as close to customers as we typically do.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.67213416),\n",
      "  NodeWithScore(node=TextNode(id_='34e2cd07-0eff-4c40-b53c-31bb95df9c5e', embedding=None, metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'sourceMetadata': {'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2022-Shareholder-Letter.pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3Awh3PwpEBL4_7LFgmFFul', 'x-amz-bedrock-kb-data-source-id': 'QSPUTYFUTO'}}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='While we have a consumer business that’s $434B in 2022, the vast majority of total market segment share in global retail still resides in physical stores (roughly 80%). And, it’s a similar story for Global IT spending, where we have AWS revenue of $80B in 2022, with about 90% of Global IT spending still on-premises and yet to migrate to the cloud. As these equations steadily flip—as we’re already seeing happen—we believe our leading customer experiences, relentless invention, customer focus, and hard work will result in significant growth in the coming years. And, of course, this doesn’t include the other businesses and experiences we’re pursuing at Amazon, all of which are still in their early days.   I strongly believe that our best days are in front of us, and I look forward to working with my teammates at Amazon to make it so.   Sincerely,   Andy Jassy President and Chief Executive Officer Amazon.com, Inc.   P.S. As we have always done, our original 1997 Shareholder Letter follows. What’s written there is as true today as it was in 1997.        1997 LETTER TO SHAREHOLDERS (Reprinted from the 1997 Annual Report)   To our shareholders:   Amazon.com passed many milestones in 1997: by year-end, we had served more than 1.5 million customers, yielding 838% revenue growth to $147.8 million, and extended our market leadership despite aggressive competitive entry.   But this is Day 1 for the Internet and, if we execute well, for Amazon.com. Today, online commerce saves customers money and precious time. Tomorrow, through personalization, online commerce will accelerate the very process of discovery. Amazon.com uses the Internet to create real value for its customers and, by doing so, hopes to create an enduring franchise, even in established and large markets.   We have a window of opportunity as larger players marshal the resources to pursue the online opportunity and as customers, new to purchasing online, are receptive to forming new relationships. The competitive landscape has continued to evolve at a fast pace.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6133713),\n",
      "  NodeWithScore(node=TextNode(id_='8b1ff235-3cdb-4199-94f1-e82836bf566b', embedding=None, metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2020-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'sourceMetadata': {'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2020-Shareholder-Letter.pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AztzPwpEBFLS6KFZCHK4B', 'x-amz-bedrock-kb-data-source-id': 'QSPUTYFUTO'}}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='We have 200 million Prime members, for a total in 2020 of $126 billion of value creation.   AWS is challenging to estimate because each customer’s workload is so different, but we’ll do it anyway, acknowledging up front that the error bars are high. Direct cost improvements from operating in the cloud versus on premises vary, but a reasonable estimate is 30%. Across AWS’s entire 2020 revenue of $45 billion, that 30% would imply customer value creation of $19 billion (what would have cost them $64 billion on their own cost $45 billion from AWS). The difficult part of this estimation exercise is that the direct cost reduction is the smallest portion of the customer benefit of moving to the cloud. The bigger benefit is the increased speed of software development – something that can significantly improve the customer’s competitiveness and top line. We have no reasonable way of estimating that portion of customer value except to say that it’s almost certainly larger than the direct cost savings. To be conservative here (and remembering we’re really only trying to get ballpark estimates), I’ll say it’s the same and call AWS customer value creation $38 billion in 2020.   Adding AWS and consumer together gives us total customer value creation in 2020 of $164 billion.        Summarizing: Shareholders $21B Employees $91B 3P Sellers $25B Customers $164B Total $301B   If each group had an income statement representing their interactions with Amazon, the numbers above would be the “bottom lines” from those income statements. These numbers are part of the reason why people work for us, why sellers sell through us, and why customers buy from us. We create value for them. And this value creation is not a zero-sum game. It is not just moving money from one pocket to another. Draw the box big around all of society, and you’ll find that invention is the root of all real value creation. And value created is best thought of as a metric for innovation.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6088701)]\n"
     ]
    }
   ],
   "source": [
    "query = \"By what percentage did AWS revenue grow year-over-year in 2021?\"\n",
    "\n",
    "response = retriever.retrieve(query)\n",
    "\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721cd10f",
   "metadata": {},
   "source": [
    "<h2>Code</h2>\n",
    "\n",
    "<h3>Using Knowledge Base within a LlamaIndex Based RAG architecture</h3>\n",
    "\n",
    "<h4>Prompt specific to the model to personalize responses</h4>\n",
    "\n",
    "Here, we will use the specific prompt below for the model to act as a financial advisor AI system that will provide answers to questions by using fact based and statistical information when possible. We will provide the Retrieve API responses from above as a part of the {context} in the prompt for the model to refer to, along with the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3c82a32-de40-4850-ba42-cb590a5c4365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(response='According to the information provided, AWS revenue grew 37% '\n",
      "                  'year-over-year in 2021. The passage states: \"This shift by '\n",
      "                  'so many companies (along with the economy recovering) '\n",
      "                  \"helped re-accelerate AWS's revenue growth to 37% YoY in \"\n",
      "                  '2021.\"',\n",
      "         source_nodes=[ NodeWithScore(node=TextNode(id_='0545a828-661d-4d3c-a725-ea4b22885416', embedding=None, metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2021-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'sourceMetadata': {'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2021-Shareholder-Letter.pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AtdzPwpEBFLS6KFZCDq4s', 'x-amz-bedrock-kb-data-source-id': 'QSPUTYFUTO'}}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='This was due in part to the uncertainty and slowing demand that so many businesses encountered, but also in part to our helping companies optimize their AWS footprint to save money. Concurrently, companies were stepping back and determining what they wanted to change coming out of the pandemic. Many concluded that they didn’t want to continue managing their technology infrastructure themselves, and made the decision to accelerate their move to the cloud. This shift by so many companies (along with the economy recovering) helped re-accelerate AWS’s revenue growth to 37% YoY in 2021.   Conversely, our Consumer revenue grew dramatically in 2020. In 2020, Amazon’s North America and International Consumer revenue grew 39% YoY on the very large 2019 revenue base of $245 billion; and, this extraordinary growth extended into 2021 with revenue increasing 43% YoY in Q1 2021. These are astounding numbers. We realized the equivalent of three years’ forecasted growth in about 15 months.   As the world opened up again starting in late Q2 2021, and more people ventured out to eat, shop, and travel, consumer spending returned to being spread over many more entities. We weren’t sure what to expect in 2021, but the fact that we continued to grow at double digit rates (with a two-year Consumer compounded annual growth rate of 29%) was encouraging as customers appreciated the role Amazon played for them during the pandemic, and started using Amazon for a larger amount of their household purchases.   This growth also created short-term logistics and cost challenges. We spent Amazon’s first 25 years building a very large fulfillment network, and then had to double it in the last 24 months to meet customer demand. As we were bringing this new capacity online, the labor market tightened considerably, making it challenging both to receive all of the inventory our vendors and sellers wanted to send us and to place that inventory as close to customers as we typically do.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.67213416),\n",
      "                        NodeWithScore(node=TextNode(id_='8286dc2f-5c99-4631-96fe-67a905491b57', embedding=None, metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2022-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'sourceMetadata': {'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2022-Shareholder-Letter.pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3Awh3PwpEBL4_7LFgmFFul', 'x-amz-bedrock-kb-data-source-id': 'QSPUTYFUTO'}}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='While we have a consumer business that’s $434B in 2022, the vast majority of total market segment share in global retail still resides in physical stores (roughly 80%). And, it’s a similar story for Global IT spending, where we have AWS revenue of $80B in 2022, with about 90% of Global IT spending still on-premises and yet to migrate to the cloud. As these equations steadily flip—as we’re already seeing happen—we believe our leading customer experiences, relentless invention, customer focus, and hard work will result in significant growth in the coming years. And, of course, this doesn’t include the other businesses and experiences we’re pursuing at Amazon, all of which are still in their early days.   I strongly believe that our best days are in front of us, and I look forward to working with my teammates at Amazon to make it so.   Sincerely,   Andy Jassy President and Chief Executive Officer Amazon.com, Inc.   P.S. As we have always done, our original 1997 Shareholder Letter follows. What’s written there is as true today as it was in 1997.        1997 LETTER TO SHAREHOLDERS (Reprinted from the 1997 Annual Report)   To our shareholders:   Amazon.com passed many milestones in 1997: by year-end, we had served more than 1.5 million customers, yielding 838% revenue growth to $147.8 million, and extended our market leadership despite aggressive competitive entry.   But this is Day 1 for the Internet and, if we execute well, for Amazon.com. Today, online commerce saves customers money and precious time. Tomorrow, through personalization, online commerce will accelerate the very process of discovery. Amazon.com uses the Internet to create real value for its customers and, by doing so, hopes to create an enduring franchise, even in established and large markets.   We have a window of opportunity as larger players marshal the resources to pursue the online opportunity and as customers, new to purchasing online, are receptive to forming new relationships. The competitive landscape has continued to evolve at a fast pace.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6133713),\n",
      "                        NodeWithScore(node=TextNode(id_='0a569506-d224-4e7a-97ab-b416e5f5549b', embedding=None, metadata={'location': {'s3Location': {'uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2020-Shareholder-Letter.pdf'}, 'type': 'S3'}, 'sourceMetadata': {'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2020-Shareholder-Letter.pdf', 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AztzPwpEBFLS6KFZCHK4B', 'x-amz-bedrock-kb-data-source-id': 'QSPUTYFUTO'}}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='We have 200 million Prime members, for a total in 2020 of $126 billion of value creation.   AWS is challenging to estimate because each customer’s workload is so different, but we’ll do it anyway, acknowledging up front that the error bars are high. Direct cost improvements from operating in the cloud versus on premises vary, but a reasonable estimate is 30%. Across AWS’s entire 2020 revenue of $45 billion, that 30% would imply customer value creation of $19 billion (what would have cost them $64 billion on their own cost $45 billion from AWS). The difficult part of this estimation exercise is that the direct cost reduction is the smallest portion of the customer benefit of moving to the cloud. The bigger benefit is the increased speed of software development – something that can significantly improve the customer’s competitiveness and top line. We have no reasonable way of estimating that portion of customer value except to say that it’s almost certainly larger than the direct cost savings. To be conservative here (and remembering we’re really only trying to get ballpark estimates), I’ll say it’s the same and call AWS customer value creation $38 billion in 2020.   Adding AWS and consumer together gives us total customer value creation in 2020 of $164 billion.        Summarizing: Shareholders $21B Employees $91B 3P Sellers $25B Customers $164B Total $301B   If each group had an income statement representing their interactions with Amazon, the numbers above would be the “bottom lines” from those income statements. These numbers are part of the reason why people work for us, why sellers sell through us, and why customers buy from us. We create value for them. And this value creation is not a zero-sum game. It is not just moving money from one pocket to another. Draw the box big around all of society, and you’ll find that invention is the root of all real value creation. And value created is best thought of as a metric for innovation.', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6088701)],\n",
      "         metadata={ '0545a828-661d-4d3c-a725-ea4b22885416': { 'location': { 's3Location': { 'uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2021-Shareholder-Letter.pdf'},\n",
      "                                                                            'type': 'S3'},\n",
      "                                                              'sourceMetadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AtdzPwpEBFLS6KFZCDq4s',\n",
      "                                                                                  'x-amz-bedrock-kb-data-source-id': 'QSPUTYFUTO',\n",
      "                                                                                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2021-Shareholder-Letter.pdf'}},\n",
      "                    '0a569506-d224-4e7a-97ab-b416e5f5549b': { 'location': { 's3Location': { 'uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2020-Shareholder-Letter.pdf'},\n",
      "                                                                            'type': 'S3'},\n",
      "                                                              'sourceMetadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3AztzPwpEBFLS6KFZCHK4B',\n",
      "                                                                                  'x-amz-bedrock-kb-data-source-id': 'QSPUTYFUTO',\n",
      "                                                                                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2020-Shareholder-Letter.pdf'}},\n",
      "                    '8286dc2f-5c99-4631-96fe-67a905491b57': { 'location': { 's3Location': { 'uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                                                                            'type': 'S3'},\n",
      "                                                              'sourceMetadata': { 'x-amz-bedrock-kb-chunk-id': '1%3A0%3Awh3PwpEBL4_7LFgmFFul',\n",
      "                                                                                  'x-amz-bedrock-kb-data-source-id': 'QSPUTYFUTO',\n",
      "                                                                                  'x-amz-bedrock-kb-source-uri': 's3://bedrock-kb-ap-south-1-874163252636/AMZN-2022-Shareholder-Letter.pdf'}}})\n"
     ]
    }
   ],
   "source": [
    "query = \"By what percentage did AWS revenue grow year-over-year in 2021?\"\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Human: You are a financial advisor AI system, and provides answers to questions by using fact based and statistical information when possible. \n",
    "Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "The response should be specific and use statistics or numbers when possible.\n",
    "\n",
    "Assistant:\"\"\"\n",
    "\n",
    "qa_template = PromptTemplate(\n",
    "    template=PROMPT_TEMPLATE, \n",
    "    template_var_mappings={\"query_str\": \"question\", \"context_str\": \"context\"}\n",
    ")\n",
    "\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"compact\", llm=llm\n",
    ")\n",
    "\n",
    "response_synthesizer.update_prompts(\n",
    "    {\"text_qa_template\": qa_template}\n",
    ")\n",
    "retrieved_results = retriever.retrieve(query)\n",
    "\n",
    "response = response_synthesizer.synthesize(query, retrieved_results)\n",
    "pp.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1cd85a",
   "metadata": {},
   "source": [
    "<h2>Conclusion</h2>\n",
    "\n",
    "We saw how easy it is to use Amazon Bedrock with LlamaIndex. Specifically we saw how LLM models form Amazon Bedrock and Knowledge base from Amazon Bedrock can be used by LlamaIndex to orchestrate the Q&A capability. \n",
    "\n",
    "<h2>Next Steps</h2>\n",
    "\n",
    "Cleaning up the resources that we created.\n",
    "\n",
    "\n",
    "<h2>Clean Up</h2>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "In case you are done with your labs and the sample codes then remember to Clean Up the resources at the end of your session by following <a href=\"https://github.com/aws-samples/amazon-bedrock-samples/opensource-libraries/knowledge-base/3_clean_up.ipynb\">3_clean_up.ipynb</a> \n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
