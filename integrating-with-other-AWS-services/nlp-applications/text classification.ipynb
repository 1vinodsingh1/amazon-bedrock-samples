{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Applications with Amazon Bedrock\n",
    "This Jupyter notebook delves into the realm of Natural Language Processing (NLP) applications using Large Language Models (LLMs) available through Amazon Bedrock. LLMs, such as Amazon Titan Text Large, have revolutionized NLP by demonstrating unparalleled language comprehension and fluency. In this notebook, we aim to provide hands-on experience to developers and researchers, showcasing how to harness the power of LLMs for micro applications, including text classification, entity recognition, sentiment analysis, and more.\n",
    "\n",
    "### Tools\n",
    "For building NLP applications using (LLMs), following tools will be used.\n",
    "\n",
    "- **AWS Lambda** is a serverless compute service that allows you to run your code without managing servers. It enables you to execute functions in response to certain events, such as API requests or data changes. For our NLP applications, we will use AWS Lambda to host and execute the inference code, which interacts with the LLM and processes the natural language inputs.\n",
    "\n",
    "- **Amazon API Gateway** is a fully managed service that makes it easy to create, publish, maintain, monitor, and secure APIs at any scale. It acts as a front-end to our AWS Lambda functions, allowing us to create a RESTful API that can be accessed by external applications. Through the API Gateway, our NLP applications will receive incoming text data and return the processed results from the language model.\n",
    "\n",
    "- **Amazon Bedrock** is a Foundation Model as a Service (FMaaS) provided by AWS that allows use of LLMs in an API driven manner. Developers can access state-of-the-art LLMs from AWS such as Amazon Titan Text and third parties such as Anthropic Claude & AI21 Jurassic. We can use Bedrock API to prompt LLMs and build our NLP applications.\n",
    "\n",
    "### Architecture\n",
    "![Architecture](./images/architecture.png)\n",
    "\n",
    "### Pre-requisites\n",
    "For you to run this notebook, you must have access to the following:\n",
    "- Python 3.9+\n",
    "- Latest `boto3` and `botocore` python SDK\n",
    "- Amazon Bedrock enabled in your account.\n",
    "- IAM role for the following:\n",
    "    - Lambda to access Amazon Bedrock"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "Before we begin executing the code snippets below, this notebook requires some dependencies. These dependencies can be downloaded using the bash script available in this folder. After downloading we can install the `boto3`, `botocore` and `awscli` freshly downloaded.\n",
    "\n",
    "Execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash ./download_dependencies.sh\n",
    "!pip install ./dependencies/botocore-1.29.162-py3-none-any.whl ./dependencies/boto3-1.26.162-py3-none-any.whl ./dependencies/awscli-1.27.162-py3-none-any.whl --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "region_name = 'us-east-1'\n",
    "bedrock = boto3.client('bedrock', region_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification\n",
    "We begin with text classification which is a fundamental and versatile task in NLP, enabling machines to automatically categorize text into predefined classes or topics based on their content. This section will demonstrate how to build a robust text classifier using an LLM. Some of the complex text classification use-cases could be:\n",
    "- Sentiment Analysis\n",
    "- Topic Categorization\n",
    "- Intent Detection\n",
    "- Language Detection\n",
    "- Toxicity Classification\n",
    "- Fake News Detection\n",
    "\n",
    "Leveraging LLMs for text classification allows us to benefit from their contextual understanding and semantic knowledge, enabling highly accurate and contextually-aware categorization. Throughout this section, we will explore the use-case of **Topic Categorization** and how to create a text classifier using few-shot learning, providing the model with a limited number of examples for each category to achieve generalized and effective classification results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt\n",
    "The input to an LLM is a prompt. A prompt includes instruction and context on how the model should act and understand the input you send in. The prompt needed to create a Text Classification application will consist of the following components:\n",
    "- **Instruction**: A concise statement explaining the role of the model and guidelines that it should consider.\n",
    "- **Categories**: A list of categories that the model should understand and choose from when the user sends in the query.\n",
    "- **Examples**: The model will interpret how the input will look like from the user and how to provide the output\n",
    "- **User Query**: The actual input text from the user.\n",
    "- **Output Indicator**: The model will generate it's output after this indicator.\n",
    "\n",
    "For this purpose we will first construct a template and later fill this in with the dynamic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Instruction: Classify the text input at the end into the categories given below, if the input text doesn't belong to any of the categories then output 'unknown'. Use the examples to understand the type of input text.\n",
    "Categories: {categories}\n",
    "Examples: \n",
    "{examples}\n",
    "\n",
    "User Input: {user_query}\n",
    "Category:\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165). LLMs can be exposed to few examples for them to understand the task and mimic the same beahvior forward. We will provide some examples of the business categories in form of `input` and `category`. Model performs good any where between 5-10 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [ \n",
    "    {\"Input\": \"Artificial intelligence is revolutionizing various industries, including healthcare and finance.\",\n",
    "    \"Category\": \"Technology\"},\n",
    "    {\"Input\": \"The soccer match between the two rival teams ended in a thrilling tie.\",\n",
    "    \"Category\": \"Sports\"},\n",
    "    {\"Input\": \"Yoga and meditation can help reduce stress and promote mental clarity.\",\n",
    "    \"Category\": \"Health and Wellness\"},\n",
    "    {\"Input\": \"Efforts to conserve water and minimize waste are vital for sustainable development.\",\n",
    "    \"Category\": \"Environment and Sustainability\"},\n",
    "    {\"Input\": \"Entrepreneurs face numerous challenges when launching a new startup.\",\n",
    "    \"Category\": \"Business and Finance\"}\n",
    "]\n",
    "categories = ['Technology', 'Sports', 'Health and Wellness', 'Environment and Sustainability', 'Business and Finance']\n",
    "examples_text = ''\n",
    "for ex in examples:\n",
    "    _in, _out = list(ex.items())\n",
    "    examples_text += f'{_in[0]}: {_in[1]}\\n{_out[0]}: {_out[1]}\\n\\n'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can take a new query from the user and invoke the model to get the output category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = 'The stock market experienced a surge in value due to positive economic indicators.'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template can then be filled in with the gathered information above to form a prompt for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(categories=', '.join(categories), examples=examples_text, user_query=user_query)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "Amazon Bedrock provides with an API interface to invoke the model using `invoke_model` API. Input to this API will the prompt we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prompt):\n",
    "    body = json.dumps({\"inputText\": prompt})\n",
    "    modelId = \"amazon.titan-tg1-large\"  \n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    category = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = predict(prompt)\n",
    "print(f'Query: {user_query}\\nCategory: {category}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see above that using the prompt we created, a completely new piece of text can be easily classified into the correct cateogory.\n",
    "\n",
    "### Validation\n",
    "Model is working with one example, now let's evaluate with a validation set to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = [\n",
    "    {\"Input\": \"The latest smartphone features a powerful processor and an impressive camera.\",\n",
    "     \"Category\": \"Technology\"},\n",
    "    {\"Input\": \"The basketball team won the championship after an intense playoff series.\",\n",
    "     \"Category\": \"Sports\"},\n",
    "    {\"Input\": \"Eating a balanced diet and exercising regularly are essential for overall well-being.\",\n",
    "     \"Category\": \"Health and Wellness\"},\n",
    "    {\"Input\": \"Renewable energy sources like solar and wind power play a crucial role in reducing carbon emissions.\",\n",
    "     \"Category\": \"Environment and Sustainability\"},\n",
    "    {\"Input\":\"The company's quarterly earnings report exceeded analysts' expectations.\",\n",
    "     \"Category\":\"Business and Finance\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, predictions = [], []\n",
    "for sample in validation_set:\n",
    "    validation_query = sample['Input']\n",
    "    prompt = prompt_template.format(categories=', '.join(categories), examples=examples_text, user_query=validation_query)\n",
    "    validation_category = predict(prompt)\n",
    "    actual.append(sample['Category'])\n",
    "    predictions.append(validation_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (sum([a==b for a, b in zip(actual, predictions)])/len(actual))*100\n",
    "print(f'Accuracy: {accuracy}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see our model is able predict the categories for our validation set perfectly with 100% accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "Now, that we have a model and a prompt in place, we can now deploy this using AWS Lambda and Amazon API Gateway. For this we will follow the steps below to create:\n",
    "\n",
    "1. Policies\n",
    "2. IAM Role and Attach policy\n",
    "3. Lambda layer with all the dependencies\n",
    "4. Lambda function and assign a role and layer\n",
    "5. API using API Gateway\n",
    "6. Integrate Lambda with API Gateway"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_policy():\n",
    "    \"\"\"\n",
    "    Create IAM policy to allow access to Amazon Bedrock\n",
    "    \"\"\"\n",
    "    iam = boto3.client('iam')\n",
    "    policy_name = f'bedrock-access-policy-{str(int(time()))}'\n",
    "    policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": \"bedrock:*\",\n",
    "                \"Resource\": \"*\"\n",
    "            },\n",
    "            {\n",
    "                'Effect': 'Allow',\n",
    "                'Action': [\n",
    "                    'logs:CreateLogGroup',\n",
    "                    'logs:CreateLogStream',\n",
    "                    'logs:PutLogEvents'\n",
    "                ],\n",
    "                'Resource': 'arn:aws:logs:*:*:*'\n",
    "            },\n",
    "            {\n",
    "                'Effect': 'Allow',\n",
    "                'Action': [\n",
    "                    'lambda:InvokeFunction'\n",
    "                ],\n",
    "                'Resource': '*'\n",
    "            },\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": \"iam:PassRole\",\n",
    "                \"Resource\": \"*\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    policy = iam.create_policy(\n",
    "        PolicyName=policy_name,\n",
    "        PolicyDocument=json.dumps(policy_document)\n",
    "    )\n",
    "    print(f\"create_policy::Created policy {policy['Policy']['Arn']}\")\n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_role(policy):\n",
    "    \"\"\"\n",
    "    Create IAM role for Lambda function\n",
    "    \"\"\"\n",
    "    iam = boto3.client('iam')\n",
    "    role_name = f'bedrock-lambda-role-{str(int(time()))}'\n",
    "    role = iam.create_role(\n",
    "        RoleName=role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps({\n",
    "            \"Version\": \"2012-10-17\",\n",
    "            \"Statement\": [\n",
    "                {\n",
    "                    \"Effect\": \"Allow\",\n",
    "                    \"Principal\": {\n",
    "                        \"Service\": \"lambda.amazonaws.com\"\n",
    "                    },\n",
    "                    \"Action\": \"sts:AssumeRole\"\n",
    "                }\n",
    "            ]\n",
    "        })\n",
    "    )\n",
    "    print(f\"create_role::Created role {role['Role']['Arn']}\")\n",
    "    iam.attach_role_policy(\n",
    "        RoleName=role_name,\n",
    "        PolicyArn=policy['Policy']['Arn']\n",
    "    )\n",
    "    print(f\"create_role::Attached policy {policy['Policy']['Arn']} to role {role['Role']['Arn']}\")\n",
    "    return role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layer():\n",
    "    \"\"\"\n",
    "    Create Lambda layer\n",
    "    \"\"\"\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    layer_name = f'bedrock-layer-{str(int(time()))}'\n",
    "    layer = lambda_client.publish_layer_version(\n",
    "        LayerName=layer_name,\n",
    "        Description='Bedrock layer',\n",
    "        Content={\n",
    "            'ZipFile': open('bedrock_layer.zip', 'rb').read()\n",
    "        },\n",
    "        CompatibleRuntimes=['python3.9']\n",
    "    )\n",
    "    print(f\"create_layer::Created layer {layer['LayerVersionArn']}\")\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lambda_file():\n",
    "    from zipfile import ZipFile\n",
    "\n",
    "    filename = \"lambdacode.zip\"\n",
    "\n",
    "    zipObj = ZipFile(filename, \"w\")\n",
    "    zipObj.write(\"lambda_code.py\")\n",
    "    zipObj.close()\n",
    "    print(f\"create_lambda_file::Created zip file {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_function(role, layer):\n",
    "    \"\"\"\n",
    "    Create Lambda function\n",
    "    \"\"\"\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    function_name = f'bedrock-lambda-{str(int(time()))}'\n",
    "    function = lambda_client.create_function(\n",
    "        FunctionName=function_name,\n",
    "        Runtime='python3.9',\n",
    "        Role=role['Role']['Arn'],\n",
    "        Handler='lambda_code.lambda_handler',\n",
    "        Code={\n",
    "            'ZipFile': open('lambdacode.zip', 'rb').read()\n",
    "        },\n",
    "        PackageType='Zip',\n",
    "        Description='NLP Lambda for Bedrock',\n",
    "        Timeout=600,\n",
    "        MemorySize=128,\n",
    "        Publish=True,\n",
    "        Layers=[\n",
    "            layer['LayerVersionArn']\n",
    "        ]\n",
    "    )\n",
    "    print(f\"create_function::Created function {function['FunctionArn']}\")\n",
    "    return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_api(function):\n",
    "    \"\"\"\n",
    "    Create API using API Gateway\n",
    "    \"\"\"\n",
    "    api_client = boto3.client('apigatewayv2')\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    api_name = f'nlp-api-{str(int(time()))}'\n",
    "    \n",
    "    api = api_client.create_api(\n",
    "        Name=api_name,\n",
    "        ProtocolType='HTTP',\n",
    "        Target=function['FunctionArn'],\n",
    "        Version='1.0',\n",
    "        RouteKey='ANY /',\n",
    "        Description='NLP API'\n",
    "    )\n",
    "    api_gateway_permissions = lambda_client.add_permission(\n",
    "        FunctionName=function['FunctionName'],\n",
    "        StatementId=f'{api_name}-permission',\n",
    "        Action='lambda:InvokeFunction',\n",
    "        Principal='apigateway.amazonaws.com'\n",
    "    )\n",
    "    print(f\"create_api_v2::Created API {api['ApiId']}\")\n",
    "    \n",
    "    return api"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create the policy and role needed for the Lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = create_policy()\n",
    "role = create_role(policy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a handler for the Lambda function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lambda_code.py\n",
    "\"\"\"\n",
    "Lambda function to invoke Amazon Bedrock for NLP task\n",
    "\"\"\"\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(os.getenv(\"LOGGING_LEVEL\", logging.INFO))\n",
    "\n",
    "MODEL_ID = os.environ.get('MODEL_ID', \"amazon.titan-tg1-large\")\n",
    "\n",
    "prompt_template = \"\"\"Instruction: Classify the text input at the end into the categories given below, if the input text doesn't belong to any of the categories then output 'unknown'. Use the examples to understand the type of input text.\n",
    "Categories: {categories}\n",
    "Examples: \n",
    "{examples}\n",
    "\n",
    "User Input: {user_query}\n",
    "Category:\n",
    "\"\"\"\n",
    "examples = [ \n",
    "    {\"Input\": \"Artificial intelligence is revolutionizing various industries, including healthcare and finance.\",\n",
    "    \"Category\": \"Technology\"},\n",
    "    {\"Input\": \"The soccer match between the two rival teams ended in a thrilling tie.\",\n",
    "    \"Category\": \"Sports\"},\n",
    "    {\"Input\": \"Yoga and meditation can help reduce stress and promote mental clarity.\",\n",
    "    \"Category\": \"Health and Wellness\"},\n",
    "    {\"Input\": \"Efforts to conserve water and minimize waste are vital for sustainable development.\",\n",
    "    \"Category\": \"Environment and Sustainability\"},\n",
    "    {\"Input\": \"Entrepreneurs face numerous challenges when launching a new startup.\",\n",
    "    \"Category\": \"Business and Finance\"}\n",
    "]\n",
    "categories = ['Technology', 'Sports', 'Health and Wellness', 'Environment and Sustainability', 'Business and Finance']\n",
    "examples_text = ''\n",
    "\n",
    "def get_examples_text():\n",
    "    for ex in examples:\n",
    "        _in, _out = list(ex.items())\n",
    "        examples_text += f'{_in[0]}: {_in[1]}\\n{_out[0]}: {_out[1]}\\n\\n'\n",
    "    return examples_text\n",
    "\n",
    "def predict(prompt):\n",
    "    bedrock = boto3.client('bedrock' , 'us-east-1')\n",
    "    body = json.dumps({\"inputText\": prompt})\n",
    "    modelId = MODEL_ID\n",
    "    accept = \"application/json\"\n",
    "    contentType = \"application/json\"\n",
    "\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    response_body = json.loads(response.get(\"body\").read())\n",
    "    output = response_body.get(\"results\")[0].get(\"outputText\")\n",
    "    return output\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    logger.info(event)\n",
    "\n",
    "    if 'body' in event:\n",
    "        body = json.loads(event['body'])\n",
    "        user_query = body.get('query')\n",
    "    \n",
    "    prompt = prompt_template.format(categories=', '.join(categories), examples=examples_text, user_query=user_query)\n",
    "    logger.info(prompt)\n",
    "    output = predict(prompt)\n",
    "\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': json.dumps(output)\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once role is in place, we can now create a zipfile from the `lambda_code.py`, a custom layer for the Lambda function and also create the function itself and attach layer with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = create_layer()\n",
    "create_lambda_file()\n",
    "function = create_function(role, layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the Lambda function to handle our requests. It's time to expose this application with the help of Amazon API Gateway. For that we will create an API and integrate it with the Lambda function created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = create_api(function)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API is created and integrated with Lambda function. In the following cell we can see the API endpoint created which can be used to send requests and get results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_uri = api['ApiEndpoint']\n",
    "endpoint_uri"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple REST API request can be made using `requests`. Our API expects JSON input with a key `query`, we will pass our user query in this payload and get the category as a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.post(\n",
    "    endpoint_uri,\n",
    "    json={\n",
    "        'query': user_query\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see below our NLP application is deployed and responding with correct category for our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = json.loads(response.content.decode('utf-8'))\n",
    "print(f'Query: {user_query}\\nCategory: {category}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Resources\n",
    "In order to not incur any unnecessary costs, it is wise to delete these resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_cloud_resources(api, function, layer, role, policy):\n",
    "    api_client = boto3.client('apigatewayv2')\n",
    "    lambda_client = boto3.client('lambda')\n",
    "    iam_client = boto3.client('iam')\n",
    "    \n",
    "    print(f\"delete_cloud_resources::Deleting API: {api['ApiId']}\")\n",
    "    api_client.delete_api(\n",
    "        ApiId=api['ApiId']\n",
    "    )\n",
    "    print(f\"delete_cloud_resources::Deleting function: {function['FunctionName']}\")\n",
    "    lambda_client.delete_function(\n",
    "        FunctionName=function['FunctionName']\n",
    "    )\n",
    "    layer_name = layer['LayerArn'].split(':')[-1]\n",
    "    print(f\"delete_cloud_resources::Deleting layer: {layer_name}\")\n",
    "    lambda_client.delete_layer_version(\n",
    "        LayerName=layer_name,\n",
    "        VersionNumber=layer['Version']\n",
    "    )\n",
    "    print(f\"delete_cloud_resources::Detaching role policy: {role['Role']['RoleName']}\")\n",
    "    iam_client.detach_role_policy(\n",
    "        RoleName=role['Role']['RoleName'],\n",
    "        PolicyArn=policy['Policy']['Arn']\n",
    "    )\n",
    "    print(f\"delete_cloud_resources::Deleting role: {role['Role']['RoleName']}\")\n",
    "    iam_client.delete_role(\n",
    "        RoleName=role['Role']['RoleName']\n",
    "    )\n",
    "    print(f\"delete_cloud_resources::Deleting policy: {policy['Policy']['Arn']}\")\n",
    "    iam_client.delete_policy(\n",
    "        PolicyArn=policy['Policy']['Arn']\n",
    "    )\n",
    "    print(f\"delete_cloud_resources::Deleted all resources\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_local_resources():\n",
    "    \"\"\"\n",
    "    Delete local resources\n",
    "    \"\"\"\n",
    "    os.remove('lambdacode.zip')\n",
    "    os.remove('bedrock_layer.zip')\n",
    "    print(f\"delete_local_resources::Deleted local resources\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_cloud_resources(api, function, layer, role, policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_local_resources()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this example we saw how easily you can create a text classification application with the help of LLMs using Amazon Bedrock, Amazon API Gateway and AWS Lambda function. This application behaved in a serverless manner and can be easily adapted to any classification use-case you might have. \n",
    "\n",
    "We used Amazon Titan Text Large as the choice of LLM, Bedrock also support other LLMs which can be used depending on the nature of task\n",
    "\n",
    "Key Takeaways:\n",
    "- LLMs can be easily used to build NLP applications\n",
    "- LLMs work good with Few-Shot examples\n",
    "- A serverless NLP application can be built with simple architectural components\n",
    "\n",
    "Recommendations:\n",
    "- Try to play around with your own data and see the behavior of the application\n",
    "- Try to switch to other models and observe behavior\n",
    "- Try other text classification use-cases such as sentiment analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock-ft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
