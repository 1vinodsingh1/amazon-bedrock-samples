model_id,latency_seconds,completion_token_count,prompt_token_count,input_token_price,output_token_pricing,mean_rouge_l_f1_score,mean_cosine_similarity,p95_latency_seconds,avg_cost_per_txn,p95_cost_per_txn,p95_completion_token_count,p95_prompt_token_count,count,overall_report
anthropic.claude-3-sonnet-20240229-v1:0,2.43617,8,365,0.001096,0.000127,0.380583,0.788797,5.338524,0.001224,0.001306,9.75,386.5,6,"The average inference latency for this workload with prompt tokens 365 (p95 is 386) and completion tokens 8 (p95 is 9) when using anthropic.claude-3-sonnet-20240229-v1:0 is 2.4362s (p95 is 5.3385s) and the average cost for 10,000 requests is $12.235 (p95 is $13.0575). The mean ROUGE-L score is 0.3806 and Cosine Similarity is 0.7888. This is based on 6 requests."
anthropic.claude-3-haiku-20240307-v1:0,1.437931,10,365,9.1e-05,1.3e-05,0.297117,0.765014,1.54034,0.000105,0.000113,12.75,386.5,6,"The average inference latency for this workload with prompt tokens 365 (p95 is 386) and completion tokens 10 (p95 is 12) when using anthropic.claude-3-haiku-20240307-v1:0 is 1.4379s (p95 is 1.5403s) and the average cost for 10,000 requests is $1.046667 (p95 is $1.125625). The mean ROUGE-L score is 0.2971 and Cosine Similarity is 0.765. This is based on 6 requests."
mistral.mixtral-8x7b-instruct-v0:1,1.694545,5,339,0.000153,4e-06,0.389167,0.761117,2.384904,0.000157,0.000166,6.75,358.5,6,"The average inference latency for this workload with prompt tokens 339 (p95 is 358) and completion tokens 5 (p95 is 6) when using mistral.mixtral-8x7b-instruct-v0:1 is 1.6945s (p95 is 2.3849s) and the average cost for 10,000 requests is $1.565167 (p95 is $1.6605). The mean ROUGE-L score is 0.3892 and Cosine Similarity is 0.7611. This is based on 6 requests."
meta.llama3-70b-instruct-v1:0,1.750033,7,347,0.00092,2.4e-05,0.396567,0.750383,1.978877,0.000944,0.001002,8.75,366.5,6,"The average inference latency for this workload with prompt tokens 347 (p95 is 366) and completion tokens 7 (p95 is 8) when using meta.llama3-70b-instruct-v1:0 is 1.75s (p95 is 1.9789s) and the average cost for 10,000 requests is $9.4405 (p95 is $10.0185). The mean ROUGE-L score is 0.3966 and Cosine Similarity is 0.7504. This is based on 6 requests."
meta.llama3-8b-instruct-v1:0,2.34923,7,347,0.000139,4e-06,0.3528,0.745953,2.577735,0.000143,0.000151,8.0,366.5,6,"The average inference latency for this workload with prompt tokens 347 (p95 is 366) and completion tokens 7 (p95 is 8) when using meta.llama3-8b-instruct-v1:0 is 2.3492s (p95 is 2.5777s) and the average cost for 10,000 requests is $1.431 (p95 is $1.514). The mean ROUGE-L score is 0.3528 and Cosine Similarity is 0.746. This is based on 6 requests."
amazon.titan-text-express-v1,1.385057,7,323,0.000258,1.2e-05,0.4521,0.720899,1.482853,0.00027,0.00029,10.0,342.5,6,"The average inference latency for this workload with prompt tokens 323 (p95 is 342) and completion tokens 7 (p95 is 10) when using amazon.titan-text-express-v1 is 1.3851s (p95 is 1.4829s) and the average cost for 10,000 requests is $2.704 (p95 is $2.9). The mean ROUGE-L score is 0.4521 and Cosine Similarity is 0.7209. This is based on 6 requests."
mistral.mistral-7b-instruct-v0:2,1.613999,30,339,5.1e-05,6e-06,0.327533,0.631595,2.320843,5.7e-05,7e-05,81.75,358.5,6,"The average inference latency for this workload with prompt tokens 339 (p95 is 358) and completion tokens 30 (p95 is 81) when using mistral.mistral-7b-instruct-v0:2 is 1.614s (p95 is 2.3208s) and the average cost for 10,000 requests is $0.568833 (p95 is $0.70125). The mean ROUGE-L score is 0.3275 and Cosine Similarity is 0.6316. This is based on 6 requests."
